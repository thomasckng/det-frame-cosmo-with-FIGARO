\documentclass[twocolumn]{aastex631}

\usepackage{showyourwork}
\usepackage{amsfonts,amssymb,amsmath}
\usepackage[nolist,nohyperlinks]{acronym}
\usepackage{bookmark}

\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\ste}[1]{\textcolor{blue}{[Ste: #1]}}

\begin{document}

\title{Inferring cosmology from gravitational waves using non-parametric detector-frame mass distribution}

\author[0000-0002-9491-1598]{Thomas~C.~K.~Ng}
\affiliation{Department of Physics, The Chinese University of Hong Kong, Shatin, Hong Kong}

\author[0000-0001-5799-4155]{Stefano~Rinaldi}
\affiliation{Institut~für~Theoretische~Astrophysik, ZAH, Universität~Heidelberg, Albert-Ueberle-Stra{\ss}e~2, 69120 Heidelberg, Germany}
\affiliation{Dipartimento di Fisica e Astronomia ``G. Galilei'', Università di Padova, Via Marzolo 8, 35122 Padova, Italy}

\author[0000-0002-3887-7137]{Otto~A.~Hannuksela}
\affiliation{Department of Physics, The Chinese University of Hong Kong, Shatin, Hong Kong}

\correspondingauthor{Thomas~C.~K.~Ng}
\email{thomas.ng@link.cuhk.edu.hk}

\begin{abstract}
    The challenge of understanding the Universe's dynamics, particularly the Hubble tension, requires precise measurements of the Hubble constant.
    Building upon the existing spectral siren method, which capitalizes on population information from gravitational wave sources, this study explores an alternative way to analyze the population data to obtain the cosmological parameters in $\Lambda$CDM.
    We will focus on how non-parametric methods, which are flexible models that can be used to agnostically reconstruct arbitrary probability densities, can be incorporated into this framework and leverage the detector-frame mass distribution to infer the cosmological parameters.
    \todo{Rewrite abstract}
\end{abstract}

% \maketitle

\begin{acronym}
    \acro{GW}{gravitational-wave}
    \acro{LVK}{LIGO-Virgo-KAGRA Collaboration}
    \acro{PE}{parameter estimation}
    \acro{CMB}{cosmic microwave background}
    \acro{EM}{electromagnetic}
    \acro{(H)DPGMM}{hierarchy of Dirichlet process Gaussian mixture models}
    \acro{BBH}{binary black hole}
    \acro{GWTC-3}{the third Gravitational-Wave Transient Catalog}
\end{acronym}

\section{Introduction}
\label{sec:introduction}

% Motivation
In recent years, the precision of cosmological measurements has improved significantly, leading to the discovery of the Hubble tension, a discrepancy between the value of the Hubble constant $H_0$ inferred from the \ac{CMB} \citep{Planck:2018vyg} and local measurements \citep{Riess:2021jrx}.
This tension has motivated the search for new methods to measure $H_0$ with high precision, and \ac{GW} sources have emerged as a promising tool for this purpose \citep{LIGOScientific:2017adf, LIGOScientific:2021aug, Ezquiaga:2022zkx}.

To infer $H_0$ from \ac{GW} sources, one needs not only the luminosity distance which can be inferred from the signal but also the redshift of the source.
Some \ac{GW} sources can be associated with \ac{EM} counterparts, allowing for the measurement of the redshift, e.g., GW170817 \citep{LIGOScientific:2017adf, Guidorzi:2017ogy}.
However, most \ac{GW} sources do not have \ac{EM} counterparts.
In this case, one can assume \ac{GW} sources are in galaxies and associate the redshift of the galaxy to the \ac{GW} source \citep{Schutz:1986gp, DelPozzo:2011vcw, Gray:2019ksv, Gray:2023wgj}.
Another alternative method is to use population statistics to infer $H_0$ by marginalizing the redshift distribution of the sources.
This method is known as the spectral siren method \citep{You:2020wju, Mastrogiovanni:2021wsd, LIGOScientific:2021aug, Ezquiaga:2022zkx}.

% Previous work
The fundamental idea of the spectral siren method is to infer cosmology by comparing the observed mass population distribution with the intrinsic mass population distribution since the observed distribution is redshifted due to the expansion of the Universe.
Assumptions about the intrinsic population model and cosmological model are required to perform the comparison.
Previous studies often infer either the intrinsic population model or the cosmological model, but not both simultaneously, due to the expensive computational cost.
\todo{Summarize previous work and add references}
However, the intrinsic population model and the cosmological model are degenerate in general, and it is necessary to infer both simultaneously.

% Non-parametric methods
To address this issue, we study an alternative method making use of non-parametric methods.
Non-parametric methods allow us to reconstruct arbitrary probability densities without making assumptions about the form of the distribution.
In our context, we can use non-parametric methods to reconstruct the observed mass population distribution directly from the data \todo{better wording?}.
This provides an intermediate observation-driven result that encodes both the intrinsic population information and the cosmological information.
By separating the reconstruction of the observed population from the inference of the intrinsic population and cosmological model, we can explore different models easily.
Furthermore, the intermediate result represents the information contained in the observed data without any assumptions about the population model, cosmological model, or selection function, which allows us to study the features of the observed population directly.

Some other studies have made use of non-parametric methods with the spectral siren framework.
\todo{Summarize previous work, add references and compare with our work}

Considering the increasing number of \ac{GW} events and the improvement of the detectors, we expect that the spectral siren method will give us an independent and precise measurement of $H_0$ which is comparable to the previous measurements \citep{Planck:2018vyg, Riess:2021jrx}.
However, performing standard hierarchical Bayesian inference with the spectral siren method is computationally expensive, and it depends on the choice of the population model and the cosmological model.
Our method provides an alternative to studying different models without performing lengthy hierarchical analysis.
This allows us to explore more models before performing the full hierarchical Bayesian inference, which makes our method a powerful diagnostic tool for model selection.

% Section outline
In Sec.~\ref{sec:method}, we describe our modified method.
In Sec.~\ref{sec:mock_data}, we present the analysis setup and results of the mock data study.
In Sec.~\ref{sec:real_data}, we apply our method to the real data from the \ac{LVK}.
In Sec.~\ref{sec:discussion}, we compare our results with other methods and discuss future directions.
Finally, we conclude in Sec.~\ref{sec:conclusion} with a summary.
\todo{Rewrite outline}

\section{Method}
\label{sec:method}
In this section, we present the framework we developed to infer both the intrinsic population model and the cosmological model simultaneously by leveraging the detector-frame mass population distribution.
In the remainder of this Section, we will make use of the notation summarized in Table~\ref{tab:notation}, mutuated from \citet{Rinaldi:2021bhm, Rinaldi:2022kyg}.

\begin{table}
    \caption{Notation}
    \begin{ruledtabular}
        \begin{tabular}{c>{\raggedright\arraybackslash}p{0.7\linewidth}}
            Notation & Description \\
            \hline
            $m_1$ & Primary mass of the \ac{GW} sources in the source frame \\
            $q$ & Mass ratio of the \ac{GW} sources \\
            $z$ & Redshift of the \ac{GW} sources \\
            $d_L$ & Luminosity distance of the \ac{GW} sources \\
            $m^z_1$ & Primary mass of the \ac{BBH} sources in the detector frame \\
            $Y_t$ & detector-frame primary mass posterior samples of the $t$-th \ac{GW} event \\
            $\mathbf{Y}$ & Set of detector-frame primary mass posterior samples of all \ac{GW} events \\
            $\Theta_i$ & Hyperparameters of the \ac{(H)DPGMM} \\
            $\mathbf{\Theta}$ & Set of hyperparameters of the \ac{(H)DPGMM} \\
            $p(m^z_1|\mathbf{\Theta})$ & Detector-frame observed primary mass population distribution reconstructed with the \ac{(H)DPGMM} \\
            $\Lambda$ & Source-frame population model \\
            $\Omega$ & Cosmological model \\
            $p(m_1|\Lambda)$ & Source-frame primary mass population distribution assuming the population model $\Lambda$ \\
            $p(m^z_1|\Lambda, \Omega)$ & Detector-frame primary mass population distribution assuming the population model $\Lambda$ and cosmological model $\Omega$ \\
            $\mathrm{det}$ & detectability of the \ac{GW} events \\
        \end{tabular}
    \end{ruledtabular}
    \label{tab:notation}
\end{table}

Specifically, we propose two major modifications to the standard spectral siren method.
First, instead of transforming the individual-event posterior samples from the detector frame to the source frame during the \ac{PE} process, we transform the population model to the detector frame before performing \ac{PE}.
Second, instead of directly computing the likelihood of the observed data given the population model, we reconstruct the observed population distribution from the data using a non-parametric method and compare it with the population model.

With these modifications, we separate the spectral siren method into two distinct parts.
The first part is the reconstruction of the observed population from the data, which does not require any assumptions about the population model, and the intermediate result is completely data-driven.
We make use of the \ac{(H)DPGMM} developed in \citet{Rinaldi:2021bhm} as a non-parametric model to reconstruct the observed population distribution.
Other assumptions including the population model, cosmological model and selection function are then incorporated in the second half.
This separation allows us to explore the impact of different assumptions easily.
The intermediate result of the first part can be reused as long as the data does not change, reducing the computational cost of the method.

Our method consists of three main steps: the non-parametric reconstruction of the detector-frame observed population, the transformation of the source-frame population model to the detector frame, and the \ac{PE}.

\subsection{Non-parametric reconstruction of detector-frame observed population}
\label{sec:reconstruction}

The first step of our method is to reconstruct the detector-frame observed population.
we choose to consider the primary mass $m_1$ of the \ac{BBH} sources, as we want to study the cosmological parameters with the spectral siren method.
In principle, we can consider more parameters at once by reconstructing not only a single-parameter observed distribution but instead a multi-parameter observed distribution.
However, that will require a more sophisticated population model in the later steps, which is beyond the scope of this work.

With the posterior samples obtained from the \ac{PE} of each \ac{GW} event, we reconstruct the observed detector-frame primary mass population distribution.
We use the \ac{(H)DPGMM} developed in \citet{Rinaldi:2021bhm} as a non-parametric model to reconstruct the observed $m^z_1$ population distribution $p(m^z_1|\mathbf{\Theta})$.
The \ac{(H)DPGMM} is a hierarchy of Gaussian mixture models with a Dirichlet process prior, which allows the model to be flexible to reconstruct arbitrary population distribution from posterior samples.
To perform the reconstruction, we use the package \textsc{figaro}\footnote{\textsc{figaro} is publicly available at \url{https://github.com/sterinaldi/FIGARO} and via \texttt{pip}.} \citep{Rinaldi:2024eep}.
Performing the reconstruction once will give a distribution $p(m^z_1|\Theta_i)$ that is consistent with $\mathbf{Y}$ with a given set of hyperparameters $\Theta_i$.
To account for the uncertainty in the reconstruction, we need to perform the reconstruction multiple times to obtain a set of distributions $p(m^z_1|\mathbf{\Theta})$, where $\mathbf{\Theta}$ is a set of $\Theta_i$.
The uncertainty of the reconstruction can then be quantified by the spread of the distributions.
It is important to note that the reconstruction is only valid in the region where the samples are present.
In Fig.~\ref{fig:simulation_reconstruction}, we show an example of the reconstruction obtained with \textsc{figaro}.

This part of the method is completely data-driven.
Therefore the intermediate result is independent of the population, cosmological model and selection function, and we can reuse the result for testing different models.
This reduces the computational cost of the method, as we only need to perform the reconstruction once to analyze different models.

\subsection{Transformation of source-frame population model}
\label{sec:transformation}

On the other hand, we assume a population model $\Lambda$ to obtain a source-frame primary mass $m_1$ population distribution $p(m_1|\Lambda)$, which represents the underlying population distribution given the model $\Lambda$.
Note that, either a parametric model can be used to only assume the form of the population distribution, or a fixed population model can be used to assume an exact population distribution.
We then transform $p(m_1|\Lambda)$ to the detector frame with a given cosmological model $\Omega$ to obtain the population distribution $p(m^z_1|\Lambda, \Omega)$ by
\begin{widetext}
\begin{equation}
    \begin{aligned}
        &p(m^z_1|\Lambda, \Omega, \mathrm{det}) \\
        &= \int p(m^z_1|m_1, z, \Lambda, \Omega, \mathrm{det}) p(m_1, z|\Lambda, \Omega, \mathrm{det}) \mathrm{d}m_1 \mathrm{d}z \\
        &= \int p(m^z_1|m_1, z) \frac{p(\mathrm{det}|m_1, z, \Lambda, \Omega)p(m_1, z|\Lambda, \Omega)}{p(\mathrm{det}|\Lambda, \Omega)} \mathrm{d}m_1 \mathrm{d}z \\
        &= \frac{1}{p(\mathrm{det}|\Lambda, \Omega)}\int \delta(m^z_1-m_1(1+z))p(\mathrm{det}|m_1, z, \Omega)p(m_1|\Lambda)p(z|\Lambda) \mathrm{d}m_1 \mathrm{d}z \\
        &\propto \int p\left(\mathrm{det}\middle|\frac{m^z_1}{1+z},z,\Omega\right)p\left(\frac{m^z_1}{1+z}\middle|\Lambda\right)p(z|\Lambda) \mathrm{d}z\,,
    \end{aligned}
    \label{eq:transformation}
\end{equation}
\end{widetext}
where $\mathrm{det}$ represents whether the event is detectable or not.
We assume the $m_1$ distribution does not evolve with $z$.
The selection effect is included in the derivation in Eq.~\eqref{eq:transformation}, specifically, the first term in the final expression, which is the selection function.
Note that the selection function in general is a function of the detector-frame mass $m^z_1$, luminosity distance $d_L$, and mass ratio $q$.
In this work, we marginalized over $q$ to study the $m_1$ population distribution only.
Due to the censoring of the low and high mass events, we consider the selection function in the transformation instead of the reconstruction.
With different $\Lambda$ or $\Omega$, the resulting $p(m^z_1|\Lambda, \Omega, \mathrm{det})$ will be different.
In Fig.~\ref{fig:simulation_transformation}, we show an example of the transformation.

Opposite to the first part of the method, this part includes the assumptions about the population and cosmological model, as well as the selection function.
After obtaining $p(m^z_1|\Lambda, \Omega, \mathrm{det})$, we can perform the \ac{PE} to infer the optimized $\Omega$ and $\Lambda$.

\subsection{Parameter estimation}
\label{sec:pe}

With $p(m^z_1|\mathbf{\Theta})$ and $p(m^z_1|\Lambda, \Omega, \mathrm{det})$ obtained from Sec.~\ref{sec:reconstruction} and Sec.~\ref{sec:transformation} respectively, we can perform the \ac{PE} to infer the free parameters in the parametric models assumed in Sec.~\ref{sec:transformation}.
The \ac{PE} is performed by comparing $p(m^z_1|\Theta_i)$ with $p(m^z_1|\Lambda, \Omega)$.
To compare the two populations, we use the Jensen-Shannon distance $d_\mathrm{JS}$ as the distance measure.
$d_\mathrm{JS}$ is calculated as
\begin{equation}
    d_\mathrm{JS}(p, q) = \sqrt{\frac{D_\mathrm{KL}(p||m) + D_\mathrm{KL}(q||m)}{2}},
\end{equation}
where $p$ and $q$ are the two distributions to be compared, $m = (p + q) / 2$, and $D_\mathrm{KL}$ is the Kullback-Leibler divergence.
$d_\mathrm{JS}$ is a symmetric and smoothed version of $D_\mathrm{KL}$, and it is bounded between 0 and 1.

For each reconstructed distribution $p(m^z_1|\Theta_i)$, we find an optimized $\Lambda_i$ and $\Omega_i$ by minimizing $d_\mathrm{JS}$.
For the minimization, we use the \textsc{scipy} \citep{2020SciPy-NMeth} implementation of the \todo{XXX} algorithm. \todo{Add reference for the algorithm}
Note that we calculate $d_\mathrm{JS}$ in the range from the minimum to the maximum of the median of the $m^z_1$ posterior samples of each \ac{GW} event
This is because the reconstruction is only valid in the region where observations are present.
As each reconstructed distribution is independent, the optimization can be performed in parallel easily, which reduces the runtime as long as computational resources are available.
In Fig.~\ref{fig:simulation_comparison}, we show an illustration of the comparison between the two populations.

The resulting distribution of the optimized parameters is not a posterior distribution in a Bayesian sense, as we do not consider the likelihood of the observed data given the population model.
Instead, it is a distribution of the optimized parameters that are consistent with the observed data, distributed according to the uncertainty in the reconstruction of the population.
That is, the uncertainty in the comparison of the two populations is not considered in the resulting distribution.
By considering this optimization procedure only, we can estimate the optimized parameters without performing computationally expensive likelihood calculations.

The analysis code is publicly available.\footnote{The analysis code is available at \url{https://github.com/thomasckng/det-frame-cosmo-with-FIGARO/tree/main/src/scripts}.}

\section{Mock data}
\label{sec:mock_data}

In this section, we test our method with a mock data study.
To prepare the mock data, we first generated $10000$ sets of $m_1$ and $z$ samples from a \textsc{power law + peak} distribution (see, e.g., Eq.~B4 in \cite{KAGRA:2021duu}) for the $m_1$ distribution and uniform distribution over comoving volume and source-frame time (see, e.g., Eq.~11 in \citet{LIGOScientific:2019zcs}) for the $z$ distribution.
Here we assumed the $m_1$ distribution does not evolve with $z$.
We then transformed the $m_1$ and $z$ samples to $m^z_1$ and $d_L$ samples.
Here we chose the $\Lambda$CDM model with parameters consistent with the Planck 2018 results \citep{Planck:2018vyg} as the cosmological model for the transformation of the samples.

After the transformation, we applied a selection function to the $m^z_1$ and $d_L$ samples.
We chose the O3 selection function from \todo{add reference} as the selection function.
Note that we marginalized over $q$ for the selection function, similar to the transformation in Sec.~\ref{sec:transformation}.
After applying the selection function, there were $262$ sets of samples left.

We then generated the $m^z_1$ posterior samples for each true $m^z_1$ sample by
\begin{gather*}
    I \sim \mathcal{N}(0, 0.03)\,,\\
    P \sim \mathcal{N}(\log(T_t)+I, 0.03)\,,\\
    Y_t = \exp(P)\,,
\end{gather*}
where $\mathcal{N}(\mu, \sigma)$ is a normal distribution with mean $\mu$ and standard deviation $\sigma$, $I$ is the difference between the true $m^z_1$ value and the measured mean in log space, $P$ is the posterior sample in the log space, $T_t$ is the true $m^z_1$ sample, and $Y_t$ is the posterior sample for the $t$-th \ac{GW} event.
For each true $m^z_1$ sample, we draw a random $I$ and generate $1000$ $Y_t$ samples.
This procedure ensures the posterior samples are positive.
After preparing the mock data, we test our method with two cases: the inference of $H_0$ only and the inference of $H_0$ and a subset of the population model parameters.

\subsection{Inference of $H_0$}
\label{sec:inference_H0}

In this subsection, we first test our method with a simplified case where we only infer $H_0$ to demonstrate the basic idea of our method.
We assume the selection function, the true population model and its parameters, and the true cosmological model and its parameters except $H_0$ are known.

We first performed the reconstruction of the observed $m^z_1$ population distribution with \textsc{figaro} as described in Sec.~\ref{sec:reconstruction}.
The result of the reconstruction is shown in Fig.~\ref{fig:simulation_reconstruction}.

\begin{figure}[h]
    \script{plot_simulation_reconstruction.py}
    \includegraphics[width=\linewidth]{figures/simulation_reconstruction.pdf}
    \caption{
        In both panels, the red line is the histogram of the median of the $m^z_1$ posterior samples of the \ac{GW} events.
        In the upper panel, the blue line is the median of the reconstructed distributions, and the shaded region represents the 68\% and 90\% credible intervals of the reconstructed distributions.
        In the lower panel, the blue lines are the single reconstructed distributions from a subset of all the reconstructed distributions.
        By combining all the single reconstructed distributions, we obtain the distribution in the upper panel.
    }
    \label{fig:simulation_reconstruction}
\end{figure}

Next, we chose the true population model we used to generate the mock data as the source-frame population model $\Lambda$.
We then transformed $p(m_1|\Lambda)$ to the detector frame with the true cosmological model we used to generate the mock data, except we did not fix $H_0$.
We performed the transformation for each $H_0$ in the range from $5$ to $150$.
After the transformation, we applied the selection function we used to generate the mock data to the transformed distribution.
Here we only free $H_0$ in the transformation to test if our method can recover the true $H_0$ while we fixed the other cosmological parameters to the true values.
The result of the transformation is shown in Fig.~\ref{fig:simulation_transformation}.

\begin{figure}[h]
    \script{plot_simulation_transformation.py}
    \includegraphics[width=\linewidth]{figures/simulation_transformation.pdf}
    \caption{
        The upper panel shows the source-frame $m_1$ population distribution, which we chose as the true population model.
        The lower panel shows the transformed detector-frame $m^z_1$ population distributions for different $H_0$, where the corresponding $H_0$ is shown in the legend.
        The population distribution is redshifted towards higher masses as $H_0$ increases, as $m^z_1 = m_1(1+z)$ and $z$ increases with $H_0$ for a given $d_L$.
        The low-mass peak is suppressed due to the selection function.
    }
    \label{fig:simulation_transformation}
\end{figure}

Finally, we performed the \ac{PE} to infer $H_0$.
For this test specifically, instead of using the \textsc{scipy} optimization algorithm, we used a grid search to find the optimized $H_0$, as the parameter space is one-dimensional.
Figure~\ref{fig:simulation_comparison} shows an illustration of the comparison between the reconstructed observed population and the transformed population for different $H_0$.
For each $H_0$, we computed the $d_\mathrm{JS}$ between the two populations and found the optimized $H_0$ that minimizes $d_\mathrm{JS}$.

\begin{figure}[h]
    \script{plot_simulation_comparison.py}
    \includegraphics[width=\linewidth]{figures/simulation_comparison.pdf}
    \caption{
        The blue line and bands are the ones from Fig.~\ref{fig:simulation_reconstruction}, which represent the reconstructed observed population.
        The other colored lines are the ones from Fig.~\ref{fig:simulation_transformation}, which represent the transformed population for different $H_0$.
        The shaded regions represent the boundaries for the calculation of $d_\mathrm{JS}$, i.e., the $d_\mathrm{JS}$ calculation only considers the non-shaded region.
    }
    \label{fig:simulation_comparison}
\end{figure}

The result of the \ac{PE} is shown in Fig.~\ref{fig:simulation_result_H0}.
The result shows that our method can recover the true $H_0$ we used to generate the mock data.

\begin{figure}[h]
    \script{plot_simulation_result_H0.py}
    \includegraphics[width=\linewidth]{figures/simulation_result_H0.pdf}
    \caption{
        The histogram shows the distribution of the optimized $H_0$.
        The vertical blue line and shaded regions represent the median, 68\%, and 90\% credible intervals of the distribution.
        The vertical orange line represents the true $H_0$ we used to generate the mock data.
        Note that the distribution only shows the uncertainty in the reconstruction.
        The uncertainty in the comparison is not considered in the distribution.
    }
    \label{fig:simulation_result_H0}
\end{figure}

\subsection{Inference of $H_0$ and $\Lambda$}
\label{sec:inference_multi}

In this subsection, we test our method with a more realistic case where we infer $H_0$ and a subset of the population model parameters.
Similar to the previous subsection, we assume only the free parameters are unknown.
We chose the power law index $\alpha$, the peak mass $\mu$, the peak width $\sigma$, and the peak weight $w$ as the free parameters.
Other parameters are the minimum and maximum mass, as well as the smoothing index of the boundaries.
These parameters might not be able to be inferred accurately with our method, as the reconstruction is only valid in the region where the samples are present and the reconstruction may be not accurate at the boundaries.

The reconstruction of the observed $m^z_1$ population distribution is the same as in the previous subsection.
Note that the same reconstruction result can be reused, as the data does not change.

Following the same procedure as in the previous subsection, except that we use the \textsc{scipy} optimization algorithm mentioned in Sec.~\ref{sec:pe} in this example, we get the result of the \ac{PE} shown in Fig.~\todo{add figure}.
The result shows that our method can infer multiple parameters simultaneously.

In principle, more parameters can be inferred with our method, for example, the present mass density $\Omega_m$ in the $\Lambda$CDM model.
However, the optimization procedure becomes more computationally expensive as the number of parameters increases.

\section{Real data}
\label{sec:real_data}

Data from \citet{LIGOScientific:2019lzm, KAGRA:2023pio}

% Power law + peak

% PL+P issue
    % Gregoire Pierra's paper

\section{Discussion}
\label{sec:discussion}

\subsection{Comparison with previous work}
\label{sec:comparison}
% diagnostic tool & model selection

\subsection{Prospective improvements}
\label{sec:prospective}
As mentioned in Sec.~\ref{sec:pe}, our method is not a Bayesian inference, as we only consider the optimization of the parameters.
To perform a full Bayesian inference, we need to develop a likelihood function that considers the comparison of the two populations.
With this likelihood, our method will give the same result as the standard hierarchical Bayesian inference, as long as the number of reconstructions is large enough.

Another potential improvement is to consider not only the primary mass distribution.
For example, we can consider the joint distribution of the primary mass and luminosity distance.
The reconstruction of the joint observed distribution can also be performed in the current framework.
However, we need a joint population model that considers both the primary mass and luminosity distance.
Performing the analysis of the joint distribution will allow us to study mass population models that evolve with redshift.
Furthermore, the inference of cosmological parameters will be more precise, as the information from the luminosity distance is also considered.

We also mentioned a limitation of the method in Sec.~\ref{sec:inference_multi}.
The runtime of the optimization procedure scales with the number of parameters.
To perform higher dimensional analysis, we need to study using, instead of $d_\mathrm{JS}$, other distance measures that allow for faster optimization.
Either a distance measure that gives a simpler geometry to be optimized or a distance measure that can be calculated faster will be useful.
Other optimization algorithms should also be considered to allow for higher dimensional analysis and faster runtime.

\section{Conclusion}
\label{sec:conclusion}

\begin{acknowledgments}
T.~N.~ and S.~R.~ acknowledge financial support from the German Excellence Strategy via the Heidelberg Cluster of Excellence (EXC 2181 - 390900948) STRUCTURES.
S.~R.~ acknowledges financial support from the European Research Council for the ERC Consolidator grant DEMOBLACK, under contract no. 770017. 
This research made use of the bwForCluster Helix: the authors acknowledge support by the state of Baden-Württemberg through bwHPC and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG.
This research has made use of data or software obtained from the Gravitational Wave Open Science Center (gwosc.org), a service of the LIGO Scientific Collaboration, the Virgo Collaboration, and KAGRA. This material is based upon work supported by NSF's LIGO Laboratory which is a major facility fully funded by the National Science Foundation, as well as the Science and Technology Facilities Council (STFC) of the United Kingdom, the Max-Planck-Society (MPS), and the State of Niedersachsen/Germany for support of the construction of Advanced LIGO and construction and operation of the GEO600 detector. Additional support for Advanced LIGO was provided by the Australian Research Council. Virgo is funded, through the European Gravitational Observatory (EGO), by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale di Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by institutions from Belgium, Germany, Greece, Hungary, Ireland, Japan, Monaco, Poland, Portugal, Spain. KAGRA is supported by Ministry of Education, Culture, Sports, Science and Technology (MEXT), Japan Society for the Promotion of Science (JSPS) in Japan; National Research Foundation (NRF) and Ministry of Science and ICT (MSIT) in Korea; Academia Sinica (AS) and National Science and Technology Council (NSTC) in Taiwan.
This paper was compiled using \textsc{showyourwork} \cite{Luger2021} to facilitate reproducibility.

\end{acknowledgments}

\bibliography{bib}

\end{document}
