\documentclass[sn-aps, pdflatex, iicol]{sn-jnl}

\usepackage{showyourwork}
\usepackage{amsfonts,amssymb,amsmath}
\usepackage[nolist,nohyperlinks]{acronym}
\usepackage{bookmark}
\usepackage{xcolor}
\usepackage{array}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{orcidlink}

\begin{document}

\title{Inferring cosmology from gravitational waves using non-parametric detector-frame mass distribution}

\author*[1]{Thomas~C.~K.~Ng\,\orcidlink{0000-0002-9491-1598}\,}\email{thomas.ng@link.cuhk.edu.hk}
\author[2,3]{Stefano~Rinaldi\,\orcidlink{0000-0001-5799-4155}\,}\email{stefano.rinaldi@uni-heidelberg.de}
\author[1]{Otto~A.~Hannuksela\,\orcidlink{0000-0002-3887-7137}\,}\email{hannuksela@phy.cuhk.edu.hk}

\affil[1]{Department of Physics, The Chinese University of Hong Kong, Shatin, Hong Kong}
\affil[2]{Institut~für~Theoretische~Astrophysik, ZAH, Universität~Heidelberg, Albert-Ueberle-Stra{\ss}e~2, 69120 Heidelberg, Germany}
\affil[3]{Dipartimento di Fisica e Astronomia ``G. Galilei'', Università di Padova, Via Marzolo 8, 35122 Padova, Italy}

\abstract{
    The challenge of understanding the Universe's dynamics, particularly the Hubble tension, requires precise measurements of the Hubble constant.
    Building upon the existing spectral-siren method, which capitalizes on population information from gravitational-wave sources, this paper explores an alternative way to analyze the population data to obtain the cosmological parameters in $\Lambda$CDM.
    We demonstrated how non-parametric methods, which are flexible models that can be used to agnostically reconstruct arbitrary probability densities, can be incorporated into this framework and leverage the detector-frame mass distribution to infer the cosmological parameters.
    We tested our method with mock data and applied it to $70$ binary black hole mergers from the third gravitational-wave transient catalog of the LIGO-Virgo-KAGRA Collaboration.
}

\maketitle

\begin{acronym}
    \acro{GW}{gravitational-wave}
    \acro{LVK}{LIGO-Virgo-KAGRA Collaboration}
    \acro{PE}{parameter estimation}
    \acro{CMB}{cosmic microwave background}
    \acro{EM}{electromagnetic}
    \acro{(H)DPGMM}{hierarchy of Dirichlet process Gaussian mixture models}
    \acro{BBH}{binary-black-hole}
    \acro{FAR}{false alarm rate}
\end{acronym}

\section{Introduction}
\label{sec:introduction}

In recent years, the precision of cosmological measurements has improved significantly, leading to the discovery of the Hubble tension, a discrepancy between the value of the Hubble constant $H_0$ inferred from the \ac{CMB} \citep{Planck:2018vyg} and local measurements \citep{Riess:2021jrx}.
This tension has motivated the search for new methods to measure $H_0$ with high precision, and \ac{GW} sources detected by the \ac{LVK} \citep{KAGRA:2013rdx, LIGOScientific:2014pky, VIRGO:2014yos, KAGRA:2020tym} have emerged as a promising tool for this purpose \citep{LIGOScientific:2017adf, LIGOScientific:2021aug, Ezquiaga:2022zkx}.

To infer $H_0$ from \ac{GW} sources, one needs not only the luminosity distance which can be inferred from the signal but also the redshift of the source.
Some \ac{GW} sources can be associated with \ac{EM} counterparts, allowing for the measurement of the redshift, e.g., GW170817 \citep{LIGOScientific:2017adf, Guidorzi:2017ogy}.
However, most \ac{GW} sources do not have \ac{EM} counterparts.
In this case, one can assume \ac{GW} sources are in galaxies and associate the redshift of the galaxy to the \ac{GW} source \citep{Schutz:1986gp, DelPozzo:2011vcw, Gray:2019ksv, Mukherjee:2020hyn, Mukherjee:2022afz, Gray:2023wgj}.
Another alternative method is to use population statistics to infer $H_0$ by marginalizing the redshift distribution of the sources.
This method is known as the spectral-siren method \citep{Farr:2019twy, You:2020wju, Mastrogiovanni:2021wsd, LIGOScientific:2021aug, Ezquiaga:2022zkx, Karathanasis:2022rtr}.

The fundamental idea of the spectral-siren method is to infer cosmology by comparing the observed mass population distribution with the intrinsic mass population distribution since the observed distribution is redshifted due to the expansion of the Universe.
The method works best when the intrinsic distribution is well understood.
However, the features present in the mass distribution are not so well characterized yet, and their astrophysical origin is a debated topic \citep{Zevin:2017evb, Mapelli:2020vfa, Zevin:2020gbd, Mandel:2018hfr, Marchant:2023wno}.
In this case, the spectral-siren method depends on the choice of the population model, which can introduce biases in the inference \citep{Mastrogiovanni:2021wsd, Mukherjee:2021rtw, Pierra:2023deu}.
Furthermore, the intrinsic distribution is degenerate with cosmology: for example, an intrinsic distribution with a linear redshift evolution is degenerate with $H_0$, as they both redshift the observed distribution in the same way.
While this example is not physical, this degeneracy still affects the inference of $H_0$.
Due to these issues, astrophysics and cosmology are tightly linked to each other, and a proper inference of the astrophysical and cosmological parameters should be done simultaneously, which makes the method computationally expensive.

A possible alternative approach, which we will propose in this paper, is to use non-parametric methods to reconstruct the observed mass population distribution directly from the data.
Non-parametric methods allow us to reconstruct arbitrary probability densities without making assumptions about the form of the distribution \citep{Rinaldi:2021bhm}.
In our context, we can use non-parametric methods to reconstruct the observed mass population distribution directly from the data.
We can then compare the reconstructed distribution with the predicted distribution from some intrinsic population model and cosmological model, which allows us to infer the model parameters by minimizing the distance between the two distributions.

This approach allows us to extract the information contained in the observed data without making assumptions about the population model, cosmological model, or selection function; at the same time, the reconstructed distribution can act as an intermediate observation-driven result that encodes both the intrinsic population information and the cosmological information.
Making use of the reconstructed distribution, we can easily explore the effect of using different models, as the reconstructed distribution can be reused for different models.
Furthermore, the intermediate result represents the information contained in the observed data without any assumptions about the population model, cosmological model, or selection function, which allows us to study the features of the observed population directly.

Other studies have made use of non-parametric methods for population studies \citep[e.g.,][]{Mandel:2016prl, Mandel:2018mve, Tiwari:2020vym, Rinaldi:2021bhm, Edelman:2021zkw, Sadiq:2021fin, Edelman:2022ydv, Callister:2023tgi, Ray:2023upk}, and now these methods are starting to be applied to the spectral siren method.
For example, \cite{Farah:2024xub} and \cite{MaganaHernandez:2024uty} used different non-parametric models to model the intrinsic mass distribution, which allows for a flexible model that can capture the features of the intrinsic distribution.

In Sec.~\ref{sec:method}, we describe our modified method in detail.
In Sec.~\ref{sec:mock_data}, we present the analysis setup and results of the mock data study.
In Sec.~\ref{sec:real_data}, we apply our method to the real data from the \ac{LVK}.
Finally, we conclude in Sec.~\ref{sec:conclusion} with a summary and outlook.

\section{Method}
\label{sec:method}

In this section, we present the framework we developed to infer both the intrinsic population model and the cosmological model simultaneously by leveraging the detector-frame mass population distribution.
In the remainder of this Section, we will make use of the notation summarized in Table~\ref{tab:notation}, taken from \cite{Rinaldi:2021bhm, Rinaldi:2022kyg}.

\begin{table}[htbp]
    \caption{Notation used in this paper}
    \begin{tabular}{cp{0.7\linewidth}}
        \toprule
        Notation & Description \\
        \midrule
        $m_1$ & Primary mass of the \ac{GW} sources in the source frame \\
        $q$ & Mass ratio of the \ac{GW} sources \\
        $z$ & Redshift of the \ac{GW} sources \\
        $d_L$ & Luminosity distance of the \ac{GW} sources \\
        $m^z_1$ & Primary mass of the \ac{BBH} sources in the detector frame \\
        $Y_t$ & detector-frame primary mass posterior probability distribution samples of the $t$-th \ac{GW} event \\
        $\mathbf{Y}$ & Set of detector-frame primary mass posterior probability distribution samples of all \ac{GW} events \\
        $\Theta_i$ & Hyperparameters of the \ac{(H)DPGMM} \\
        $\mathbf{\Theta}$ & Set of hyperparameters of the \ac{(H)DPGMM} \\
        $p(m^z_1|\mathbf{\Theta})$ & Detector-frame observed primary mass population distribution reconstructed with the \ac{(H)DPGMM} \\
        $\Lambda$ & Source-frame population model \\
        $\Omega$ & Cosmological model \\
        $p(m_1|\Lambda)$ & Source-frame primary mass population distribution assuming the population model $\Lambda$ \\
        $p(m^z_1|\Lambda, \Omega)$ & Detector-frame primary mass population distribution assuming the population model $\Lambda$ and cosmological model $\Omega$ \\
        $\mathrm{det}$ & detectability of the \ac{GW} events \\
        \botrule
    \end{tabular}
    \label{tab:notation}
\end{table}

Specifically, we propose two major modifications to the standard spectral-siren method.
First, instead of transforming the individual-event posterior probability distribution samples from the detector frame to the source frame during the \ac{PE} process, we transform the population model to the detector frame before performing \ac{PE}.
Second, instead of directly computing the likelihood of the observed data given the population model, we reconstruct the observed population distribution from the data using a non-parametric method and compare it with the population model.

With these modifications, we separate the spectral-siren method into two distinct parts.
The first part is the reconstruction of the observed population from the data, which does not require any assumptions about the population model, and the intermediate result is completely data-driven.
We make use of the \ac{(H)DPGMM} developed in \cite{Rinaldi:2021bhm} as a non-parametric model to reconstruct the observed population distribution.
In the second part, we make use of all the other assumptions, namely the population model, cosmological model and selection function, to transform the source-frame population model into the detector frame.
This separation allows us to explore the impact of different assumptions easily.
The intermediate result of the first part can be reused as long as the data does not change, reducing the computational cost of the method.

Our method consists of three main steps: the non-parametric reconstruction of the detector-frame observed population, the transformation of the source-frame population model to the detector frame, and the remapping of the reconstructed distribution to the model parameters.

\subsection{Non-parametric reconstruction of detector-frame observed population}
\label{sec:reconstruction}

The first step of our method is to reconstruct the detector-frame observed population.
We choose to consider the primary mass $m_1$ of the \ac{BBH} sources, as we want to study the cosmological parameters with the spectral-siren method.
In principle, we can consider more parameters at once by reconstructing not only a single-parameter observed distribution but instead a multi-parameter observed distribution.
However, that will require a more sophisticated population model in the later steps, which is beyond the scope of this work.

With the posterior probability distribution samples obtained from the \ac{PE} of each \ac{GW} event, we reconstruct the observed detector-frame primary mass population distribution.
We use the \ac{(H)DPGMM} developed in \cite{Rinaldi:2021bhm} as a non-parametric model to reconstruct the observed $m^z_1$ population distribution $p(m^z_1|\mathbf{\Theta})$.
In a nutshell, (H)DPGMM approximates the underlying probability density with a (potentially infinite) Gaussian mixture model,
\begin{equation}
    p(m_1^z) \simeq \sum_j^\infty w_j \mathcal{N}(m_1^z|\mu_j,\sigma_j)\,,
\end{equation}
where the relative weights of the components are inferred using a Dirichlet process. In what follows, we will refer to the (H)DPGMM parameters collectively as $\Theta = \{\mathbf{w},\boldsymbol\mu,\boldsymbol\sigma\}$.
To perform the reconstruction, we use the package \textsc{figaro}\footnote{\textsc{figaro} is publicly available at \url{https://github.com/sterinaldi/FIGARO} and via \texttt{pip}.} \citep{Rinaldi:2024eep}.
Performing the reconstruction once will give a distribution $p(m^z_1|\Theta_i)$ that is consistent with $\mathbf{Y}$ with a given set of hyperparameters $\Theta_i$.
To account for the uncertainty in the reconstruction, we need to perform the reconstruction multiple times to obtain a set of distributions $p(m^z_1|\mathbf{\Theta})$, where $\mathbf{\Theta}$ is a set of $\Theta_i$.
The uncertainty of the reconstruction can then be quantified by the spread of the distributions.
It is important to note that the reconstruction is only valid in the region where the samples are present and cannot be extrapolated to regions where no samples are present.
In Fig.~\ref{fig:simulation_reconstruction}, we show an example of the reconstruction obtained with \textsc{figaro}.

This part of the method is completely data-driven.
Therefore, the intermediate result is independent of the population, cosmological model and selection function, and we can reuse the result for testing different models.
This reduces the computational cost of the method, as we only need to perform the reconstruction once to analyze different models.

\subsection{Transformation of source-frame population model}
\label{sec:transformation}

On the other hand, we assume a population model $\Lambda$ to obtain a source-frame primary mass $m_1$ population distribution $p(m_1|\Lambda)$, which represents the underlying population distribution given the model $\Lambda$.
Note that, either a parametric model can be used to only assume the form of the population distribution, or a fixed population model can be used to assume an exact population distribution.
We then transform $p(m_1|\Lambda)$ to the detector frame with a given cosmological model $\Omega$ to obtain the population distribution $p(m^z_1|\Lambda, \Omega)$ by
\begin{equation}
    \mathtoolsset{multlined-width=0.89\displaywidth}
    \begin{aligned}
        &p(m^z_1|\Lambda, \Omega, \mathrm{det}) \\
        &\begin{multlined}
            = \int p(m^z_1|m_1, z, \Lambda, \Omega, \mathrm{det}) \\ \times p(m_1, z|\Lambda, \Omega, \mathrm{det}) \mathrm{d}m_1 \mathrm{d}z
        \end{multlined} \\
        &\begin{multlined}
            = \int p(m^z_1|m_1, z) \\ \times \frac{p(\mathrm{det}|m_1, z, \Lambda, \Omega)p(m_1, z|\Lambda, \Omega)}{p(\mathrm{det}|\Lambda, \Omega)} \mathrm{d}m_1 \mathrm{d}z
        \end{multlined} \\
        &\begin{multlined}
            = \frac{1}{p(\mathrm{det}|\Lambda, \Omega)}\int \delta(m^z_1-m_1(1+z)) \\ \times p(\mathrm{det}|m_1, z, \Omega)p(m_1|\Lambda)p(z|\Lambda, \Omega) \mathrm{d}m_1 \mathrm{d}z
        \end{multlined}\\
        &\begin{multlined}
            \propto \int p\left(\mathrm{det}\middle|\frac{m^z_1}{1+z},z,\Omega\right) \\ \times p\left(\frac{m^z_1}{1+z}\middle|\Lambda\right)p(z|\Lambda, \Omega) \mathrm{d}z\,,
        \end{multlined}
    \end{aligned}
    \label{eq:transformation}
\end{equation}
where $\mathrm{det}$ represents whether the event is detectable or not.
We assume the $m_1$ distribution does not evolve with $z$.

The selection effects are included in the derivation in Eq.~\eqref{eq:transformation} via the first term in the final expression, using the selection function.
In general, the selection function is a function of all the intrinsic binary parameters: the most important, however, are the component masses and the luminosity distance $d_L$.
In this work, since our intrinsic distribution includes only $m_1$ and $z$, we marginalized out the mass ratio dependence of the selection function assuming an intrinsic distribution $p(q) \propto q^{1.1}$.

We opted for reconstructing the observed distribution with the non-parametric method and filtering the observed distribution rather than following the more standard procedure of agnostically reconstructing the intrinsic distribution and comparing it to our astrophysical model to circumvent the limits of non-parametric methods concerning extrapolation.
If the selection function effectively censors one area of the parameter space, such as the low-mass, high-redshift binaries, a data-driven only method will not be able to characterize the distribution in that specific area, leading to diverging uncertainties in the reconstructed distribution and thus making the whole inference scheme pointless. Conversely, if we model the observed distribution and filter the intrinsic distribution model, we are still not able to constrain the population behavior in the censored region but the inference will yield some results.
This way of including selection effects in the analysis, albeit simple and straightforward, is only an approximation of the real selection process, as pointed out in \cite{Essick:2023upv}: nonetheless, the large uncertainties currently associated with \ac{GW} measurements are most likely to be dominant with respect to the bias induced by this approximation.
Therefore, we opted to include the selection function in the transformation itself, deferring the investigation of properly including selection effects in the reconstruction of the observed distribution in a future paper.

Qualitatively, the transformation described in Eq.~\eqref{eq:transformation} redshifts the source-frame intrinsic population distribution to the detector frame, where the redshift is determined by the cosmological model.
The selection function is then applied to the redshifted distribution to obtain the detector-frame observed population distribution.
With different $\Lambda$ or $\Omega$, the resulting $p(m^z_1|\Lambda, \Omega, \mathrm{det})$ will be different.
In Fig.~\ref{fig:simulation_transformation}, we show an example of the transformation.

In contrast to the first part of the method, this part includes the assumptions about the population and cosmological model, as well as the selection function.
After obtaining $p(m^z_1|\Lambda, \Omega, \mathrm{det})$, we can perform the remapping to obtain the optimized $\Omega$ and $\Lambda$.

\subsection{Remapping to model parameters}
\label{sec:remapping}

With $p(m^z_1|\mathbf{\Theta})$ and $p(m^z_1|\Lambda, \Omega, \mathrm{det})$ obtained from Sec.~\ref{sec:reconstruction} and Sec.~\ref{sec:transformation} respectively, we need a way of translating each realization of the reconstructed distribution to a set of population and cosmological parameters.
To do so, we define a notion of "closeness" using the Jensen-Shannon distance $d_\mathrm{JS}$ between the two distributions.
$d_\mathrm{JS}$ is calculated as
\begin{equation}
    d_\mathrm{JS}(p, q) = \sqrt{\frac{D_\mathrm{KL}(p||m) + D_\mathrm{KL}(q||m)}{2}},
\end{equation}
where $p$ and $q$ are the two distributions to be compared, $m = (p + q) / 2$, and $D_\mathrm{KL}$ is the Kullback-Leibler divergence.
$d_\mathrm{JS}$ is a symmetric and smoothed version of $D_\mathrm{KL}$, and it is bounded between 0 and 1.

For each reconstructed distribution $p(m^z_1|\Theta_i)$, we find an optimized $\Lambda_i$ and $\Omega_i$ by minimizing $d_\mathrm{JS}$.
For the minimization, we use the \textsc{scipy} \citep{2020SciPy-NMeth} implementation of the modified Powell algorithm.
Note that we calculate $d_\mathrm{JS}$ in the range from the minimum to the maximum of the median of the $m^z_1$ posterior probability distribution samples of each \ac{GW} event.
This is because the reconstruction is only valid in the region where observations are present as mentioned in Sec.~\ref{sec:reconstruction}.
In Fig.~\ref{fig:simulation_comparison}, we show an illustration of the comparison between the two populations.

The resulting distribution of the optimized parameters is not a posterior probability distribution in a Bayesian sense, as we do not consider the likelihood of the observed data given the population model.
Instead, it is a distribution of the optimized parameters that are consistent with the observed data, distributed according to the uncertainty in the reconstruction of the population.
That is, the uncertainty in the comparison of the two populations is not considered in the resulting distribution.

The optimization procedure is highly efficient as it does not scale with the number of \ac{GW} events, since the optimization is performed for each reconstructed distribution independently.
Therefore, even as the number of \ac{GW} events increases, the runtime of the optimization remains constant, making our method scalable and robust for future large datasets.
This is advantageous for performing the analysis with different models when more \ac{GW} events are available, as the reconstruction can be reused.
Other than that, the optimization procedure can be performed in parallel for each reconstructed distribution, as each reconstructed distribution is independent.
This reduces the runtime as long as computational resources are available.

The analysis code we developed to implement the method presented in this section and the results of the following sections are publicly available on GitHub\footnote{\url{https://github.com/thomasckng/det-frame-cosmo-with-FIGARO/tree/main/src/scripts}} and Zenodo \citep{ng_2024_13968239} respectively.

\section{Mock data}
\label{sec:mock_data}

In this section, we test our method with a mock data study.
To prepare the mock data, we first generated \variable{output/n_true_samples.txt} sets of $m_1$ and $z$ samples from a \textsc{power law + peak} distribution (see, e.g., Eq.~B4 in \cite{KAGRA:2021duu}) for the $m_1$ distribution and uniform distribution over comoving volume and source-frame time (see, e.g., Eq.~8 in \cite{KAGRA:2021duu}) for the $z$ distribution.
Here we assumed the $m_1$ distribution does not evolve with $z$.
We then transformed the $m_1$ and $z$ samples to $m^z_1$ and $d_L$ samples.
Here we chose the $\Lambda$CDM model with parameters consistent with the results in \cite{Planck:2018vyg} as the cosmological model for the transformation of the samples.

After the transformation, we applied a selection function to the $m^z_1$ and $d_L$ samples.
We used the physically modelled selection function implemented in \cite{Lorenzo-Medina:2024opt}.
Note that we marginalized over $q$ for the selection function, similar to the transformation in Sec.~\ref{sec:transformation}.
After applying the selection function, which filters out the non-detectable events based on their $m^z_1$ and $d_L$, we retained \variable{output/n_obs_samples.txt} sets of samples for further analysis.

We then generated the $m^z_1$ posterior probability distribution samples for each true $m^z_1$ sample by
\begin{gather*}
    I \sim \mathcal{N}(0, 0.03)\,,\\
    P \sim \mathcal{N}(\log(T_t)+I, 0.03)\,,\\
    Y_t = \exp(P)\,,
\end{gather*}
where $\mathcal{N}(\mu, \sigma)$ is a normal distribution with mean $\mu$ and standard deviation $\sigma$, $I$ is the difference between the true $m^z_1$ value and the measured mean in log space, $P$ is the posterior probability distribution sample in the log space, $T_t$ is the true $m^z_1$ sample, and $Y_t$ is the posterior probability distribution sample for the $t$-th \ac{GW} event.
For each true $m^z_1$ sample, we draw a random $I$ and generate $1000$ $Y_t$ samples.
This procedure ensures the posterior probability distribution samples are positive.
After preparing the mock data, we test our method with two cases: the inference of $H_0$ only and the inference of $H_0$ and a subset of the population model parameters.

\subsection{Inference of $H_0$}
\label{sec:inference_H0}

In this subsection, we first test our method with a simplified case where we only infer $H_0$ to demonstrate the basic idea of our method.
We assume the selection function, the true mass and redshift population model and its parameters, and the true cosmological model and its parameters except $H_0$ are known.

We first reconstructed the observed detector-frame mass population distribution with \textsc{figaro} as described in Sec.~\ref{sec:reconstruction}.
The result of the reconstruction is shown in Fig.~\ref{fig:simulation_reconstruction}.
\begin{figure}
    \script{plot_simulation_reconstruction.py}
    \includegraphics[width=\linewidth]{figures/simulation_reconstruction.pdf}
    \caption{
        Top: non-parametric reconstruction of the observed distribution using 315 GW events (red histogram). The blue line marks the median of the reconstructed distributions, and the shaded regions represent the corresponding 68\% and 90\% credible intervals.
        Bottom: subset of individual draws for the non-parametric reconstruction.
    }
    \label{fig:simulation_reconstruction}
\end{figure}

Next, under the assumption that the population model, cosmological model and selection function are known, except for the value of $H_0$, we can perform the transformation mentioned in Sec.~\ref{sec:transformation}.
Following Eq.~\eqref{eq:transformation}, we can write the observed detector-frame mass population distribution as
\begin{equation}
    \mathtoolsset{multlined-width=0.89\displaywidth}
    \begin{aligned}
        &p(m^z_1|\Lambda, \Omega(H_0), \mathrm{det}) \\
        &\begin{multlined}
            \propto \int p\left(\mathrm{det}\middle|\frac{m^z_1}{1+z},z,\Omega(H_0)\right) \\ \times p\left(\frac{m^z_1}{1+z}\middle|\Lambda\right)p(z|\Lambda, \Omega(H_0)) \mathrm{d}z\,,
        \end{multlined}
    \end{aligned}
\end{equation}
where $\Omega(H_0)$ is the cosmological model with $H_0$ as a free parameter.
The result of the transformation is shown in Fig.~\ref{fig:simulation_transformation}.
\begin{figure}
    \script{plot_simulation_transformation.py}
    \includegraphics[width=\linewidth]{figures/simulation_transformation.pdf}
    \caption{
        Top: source-frame $m_1$ population distribution.
        Bottom: detector-frame $m^z_1$ observed distribution for different $H_0$ values. The low-mass peak is suppressed due to the selection function.
    }
    \label{fig:simulation_transformation}
\end{figure}

We then applied our optimization scheme to each reconstructed distribution to infer the optimized $H_0$.
In this simplified case, since the parameter space is one-dimensional, instead of using the optimization algorithm, we relied on a grid-based search to find the optimized $H_0$ between $5$ and $150$ $\mathrm{km}\,\mathrm{s}^{-1}\,\mathrm{Mpc}^{-1}$.
For each $H_0$, we computed the $d_\mathrm{JS}$ between the two populations and found the optimized $H_0$ that minimizes $d_\mathrm{JS}$.
Figure~\ref{fig:simulation_comparison} shows an illustration of the comparison between the reconstructed observed population and the transformed population for different $H_0$.
\begin{figure}
    \script{plot_simulation_comparison.py}
    \includegraphics[width=\linewidth]{figures/simulation_comparison.pdf}
    \caption{
        Comparison between the reconstructed observed distribution (blue line and shaded areas) and the predicted observed distribution with different $H_0$ choices. The gray shaded areas mark the boundaries for the $d_\mathrm{JS}$ calculation.
    }
    \label{fig:simulation_comparison}
\end{figure}

The result of the remapping is shown in Fig.~\ref{fig:simulation_result_H0}.
\begin{figure}
    \script{plot_simulation_result_H0.py}
    \includegraphics[width=\linewidth]{figures/simulation_result_H0.pdf}
    \caption{
        Optimized $H_0$ posterior distribution.
        The vertical blue line and shaded areas represent the median, 68\% and 90\% credible intervals respectively.
    }
    \label{fig:simulation_result_H0}
\end{figure}
The recovered $H_0$ distribution, whose uncertainty budget comes from the remapping of the individual-\ac{PE} uncertainty in the non-parametric reconstruction, is consistent with the simulated value.

\subsection{Inference of $H_0$ and $\Lambda$}
\label{sec:inference_multi}

In this subsection, we test our method with a more realistic case where we infer $H_0$ and a subset of the population model parameters.
Similar to the previous subsection, we assume perfect knowledge of both models, the selection function and all the parameters that are not objects of the inference.
Other than $H_0$, we included the power law index $\alpha$, the peak mass $\mu$, and the peak width $\sigma$ of the \textsc{power law + peak} model as the free parameters in the analysis.
The minimum mass $m_\mathrm{min}$ and maximum mass $m_\mathrm{max}$, and the range of mass tapering at the low mass end $\delta$ are fixed.
These parameters, which control the boundary features of the observed population distribution, were chosen because the reconstructions are only valid in the region where the samples are present, and the reconstructed distributions may not be accurate at the boundaries depending on the boundary features of the observed population distribution.
In principle, more parameters can be inferred with our method, for example, the peak weight $w$ in the mass population model and the present mass density $\Omega_m$ in the $\Lambda$CDM model.
However, the optimization procedure becomes more computationally expensive as the number of parameters increases, therefore, we only chose a subset of the parameters to demonstrate the idea of our method.

The reconstruction of the observed $m^z_1$ population distribution is the same as in the previous subsection.
This also shows that the reconstruction is independent of the population model, cosmological model, and selection function, and we can reuse the result for different analysis setups.
As long as the events included in the analysis do not change, the reconstruction can be reused.
With more and more events in the near future, the standard spectral-siren method may not be feasible to apply, and this feature of our method can be advantageous.

In this example, instead of transforming the source-frame population model to the detector frame for each $H_0$ and performing a grid search, we define a function that calculates $d_\mathrm{JS}$ for a given set of the free parameters.
We then use the optimization algorithm mentioned in Sec.~\ref{sec:remapping} to find the optimized free parameters that minimize $d_\mathrm{JS}$.
The optimization method requires bounds for the free parameters, which we show in Table~\ref{tab:bounds}.
\begin{table}[htbp]
    \caption{Free parameter bounds for the joint inference presented in Section~\ref{sec:inference_multi}.}
    \begin{tabular}{cc}
        \toprule
        Parameter & Bounds \\
        \midrule
        $H_0$ & $[10, 300]$ \\
        $\alpha$ & $[1.01, 10]$ \\
        $\mu$ & $[10, 70]$ \\
        $\sigma$ & $[0.01, 10]$ \\
        \botrule
    \end{tabular}
    \label{tab:bounds}
\end{table}
The initial guesses for the optimization are chosen randomly from a uniform distribution within the bounds.
The result of the remapping is shown in Fig.~\ref{fig:simulation_result_multi}.
\begin{figure}
    \script{plot_simulation_result_multi.py}
    \includegraphics[width=\linewidth]{figures/simulation_result_multi.pdf}
    \caption{
        Optimized parameter distribution for the mock data inference. Simulated values are marked in red.
    }
    \label{fig:simulation_result_multi}
\end{figure}
The recovered distribution, whose uncertainty budget comes from the remapping of the individual-\ac{PE} uncertainty in the non-parametric reconstruction, is consistent with the simulated values.

This is an expected result, as the mock data is generated with the same population model and cosmological model we used in the analysis.
We can also see that the uncertainty in $H_0$ is larger compared to the analysis in Sec.~\ref{sec:inference_H0}, as more parameters are inferred simultaneously.
The uncertainty in $\sigma$ is relatively large, this may be due to the large uncertainty in the reconstruction at the gap between the low-mass and high-mass peaks, which can be seen in 
Fig.~\ref{fig:simulation_reconstruction}.

\section{Real data}
\label{sec:real_data}

In this section, we apply our method to the \ac{GW} events released by the \ac{LVK} as part of the GWTC-2.1 \cite{LIGOScientific:2021usb, ligo_scientific_collaboration_and_virgo_2022_6513631} and GWTC-3 \cite{KAGRA:2021vkt, ligo_scientific_collaboration_and_virgo_2023_8177023} catalogs.
We included all $70$ events labeled as BBH in Table~I of \cite{KAGRA:2021duu}, these correspond to all the events with $\mathrm{FAR_{min}} < 1\, \mathrm{yr}^{-1}$, where $\mathrm{FAR_{min}}$ is the smallest \ac{FAR} among all search pipelines.
These events are different from the events used in \cite{LIGOScientific:2021aug}, where the authors use a \ac{FAR} threshold of $\mathrm{FAR_{min}} < 0.25\, \mathrm{yr}^{-1}$, therefore the results we present here might be slightly different from the ones in \cite{LIGOScientific:2021aug}.
We opted for a larger \ac{FAR} threshold -- consistent, however, with the one used in population studies such as \cite{KAGRA:2021duu} -- to have a larger number of events to include in the non-parametric analysis.

Similar to Sec.~\ref{sec:mock_data}, we first reconstructed the observed $m^z_1$ population distribution.
We use the posterior probability distribution samples of the \ac{GW} events from \cite{LIGOScientific:2019lzm, KAGRA:2023pio}.
$10000$ samples are randomly drawn from the posterior probability distribution samples of each \ac{GW} event to perform the reconstruction.
The result of the reconstruction is shown in Fig.~\ref{fig:real_reconstruction}.
\begin{figure}
    \script{plot_real_reconstruction.py}
    \includegraphics[width=\linewidth]{figures/real_reconstruction.pdf}
    \caption{
        Median non-parametric reconstruction (blue line) and median values of the $m^z_1$ posterior probability distribution samples of the \ac{GW} events (red histogram). The shaded regions represent the 68\% and 90\% credible intervals for the non-parametric reconstruction.
    }
    \label{fig:real_reconstruction}
\end{figure}

Next, we chose the \textsc{power law + peak} model as the source-frame population model $\Lambda$ and the $\Lambda$CDM model as the cosmological model $\Omega$.
For the redshift population model, instead of the uniform distribution over comoving volume and source-frame time, we used the \textsc{power law} redshift evolution model described in \cite{KAGRA:2021duu}.
Similar to Sec.~\ref{sec:inference_multi}, we fixed some parameters of the population model and the cosmological model.
For the cosmological model, we fixed the parameters to the results from \cite{Planck:2018vyg} except $H_0$.
For the population model, we fixed $\sigma$, $w$, $m_\mathrm{min}$, $m_\mathrm{max}$, and $\delta$ to the results from \cite{LIGOScientific:2021aug}.
Note that the fixed parameters are not necessarily the true values, but they can be considered as a reasonable guess for the parameters.
The fixed parameters of the population model are shown in Table~\ref{tab:fixed_parameters}.
\begin{table}[htbp]
    \caption{Fixed parameters of the $\Lambda$CDM model (left) and the \textsc{power law + peak} model (right).}
    \begin{tabular}{cc|cc}
        \toprule
        Parameter & Value & Parameter & Value  \\
        \midrule
         & & $w$ & $0.024$ \\
        $\Omega_m$ & $0.315$ & $\sigma$ & $3.8\ \mathrm{M}_\odot$\\
        $\Omega_\Lambda$ & $0.685$ & $m_\mathrm{min}$ & $5\ \mathrm{M}_\odot$ \\
        $w$ & $-1$ & $m_\mathrm{max}$ & $109\ \mathrm{M}_\odot$ \\
         & & $\delta$ & $4.9\ \mathrm{M}_\odot$\\
        \botrule
    \end{tabular}
    \label{tab:fixed_parameters}
\end{table}

We then perform the remaining steps similar to Sec.~\ref{sec:inference_multi}.
We set the bounds for $\kappa$ to $[-10, 10]$, and the bounds for other free parameters are the same as in Table~\ref{tab:bounds}.
The result of the remapping is shown in Fig.~\ref{fig:real_result_multi}, and it is consistent with the posterior distribution reported in \cite{KAGRA:2021duu}.
\begin{figure}
    \script{plot_real_result_multi.py}
    \includegraphics[width=\linewidth]{figures/real_result_multi.pdf}
    \caption{
        Optimized parameter distribution for the real data inference.
    }
    \label{fig:real_result_multi}
\end{figure}
The result implies that \variable{output/real_H0.txt}, with symmetric $90\%$-credible intervals around the median.
The uncertainty is much smaller than the one reported in \cite{KAGRA:2021duu} ($H_0 = 50^{+37}_{-30} \, \mathrm{km/s/Mpc}$), mainly because it only includes the uncertainty from the reconstruction, which underestimates the true uncertainty which also includes the mismatch between the population model and the observed population distribution.
Figure \ref{fig:real_result_multi} shows a peak in the marginalized posterior distribution of $H_0$ around $70\, \mathrm{km/s/Mpc}$.
This means a significant fraction of the reconstructed observed population distribution has an optimized $H_0$ around $70\, \mathrm{km/s/Mpc}$, which again does not include the uncertainty from the mismatch between the population model and the observed population distribution.
The peak should be interpreted as an artifact of the optimization procedure.

This analysis we report here is a proof of concept of the method presented in this paper, and we simply aim to demonstrate that our method can be applied to real data with relatively little effort.
To perform a detailed analysis, a more comprehensive configuration that considers different population models, cosmological models, and selection functions is required, as well as a more robust optimization scheme to include more astrophysical parameters.

\section{Conclusion}
\label{sec:conclusion}

In this paper, we proposed a method to infer both the intrinsic population model and the cosmological model simultaneously by leveraging the detector-frame mass population distribution and making use of non-parametric methods.
We demonstrated the method with a mock data study and applied it to the real data from the \ac{LVK}.
With the numbers of observed \ac{GW} events that are expected to grow larger and larger, potentially hitting the thousand mark by the end of the fifth observing run, performing a complete analysis from scratch with different astrophysical models will soon become too computationally expensive.
The method we propose in this paper can help mitigate this issue by providing a fast and efficient way to explore different models before performing the full hierarchical Bayesian inference, especially keeping in mind that, if a wrong population model is chosen, the inference result will be biased \citep{Mukherjee:2021rtw, Mastrogiovanni:2021wsd, Pierra:2023deu, LIGOScientific:2020kqk, KAGRA:2021duu}.
This makes our method a powerful diagnostic tool for model selection.

To further improve the method, there are several directions we can explore.
First, as mentioned in Sec.~\ref{sec:remapping}, our method is not a Bayesian inference, as we only consider the optimization of the parameters.
To perform a full Bayesian inference, we need to develop a likelihood function that considers the comparison of the two populations.
With this likelihood, our method will give the same result as the standard hierarchical Bayesian inference, as long as the number of reconstructions is large enough.
This will allow us to perform efficient Bayesian model selection, as different models can be tested without repeating the reconstruction of the observed population distribution.
We will explore this possibility in future work.

Another potential improvement is to consider not only the primary mass distribution.
For example, we can consider the joint distribution of the primary mass, mass ratio, and redshift.
The reconstruction of the joint observed distribution can also be performed in the current framework.
However, we need a joint population model that considers all the parameters, including the possible correlations between the parameters.
Performing the analysis of the joint distribution will allow us to study mass population models that evolve with redshift.
Furthermore, the inference of cosmological parameters will be more precise, as the information from the luminosity distance is also considered.

\backmatter

\bmhead{Acknowledgements}

We thank Grégoire Pierra for helpful discussions.
T.~N. and S.~R. acknowledge financial support from the German Excellence Strategy via the Heidelberg Cluster of Excellence (EXC 2181 - 390900948) STRUCTURES.
S.~R. acknowledges financial support from the European Research Council for the ERC Consolidator grant DEMOBLACK, under contract no. 770017. 
We acknowledge the use of computing facilities supported by grants from the Croucher Innovation Award from the Croucher Foundation Hong Kong.
This research made use of the bwForCluster Helix: the authors acknowledge support by the state of Baden-Württemberg through bwHPC and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG.
This research has made use of data or software obtained from the Gravitational Wave Open Science Center (gwosc.org), a service of the LIGO Scientific Collaboration, the Virgo Collaboration, and KAGRA. This material is based upon work supported by NSF's LIGO Laboratory which is a major facility fully funded by the National Science Foundation, as well as the Science and Technology Facilities Council (STFC) of the United Kingdom, the Max-Planck-Society (MPS), and the State of Niedersachsen/Germany for support of the construction of Advanced LIGO and construction and operation of the GEO600 detector. Additional support for Advanced LIGO was provided by the Australian Research Council. Virgo is funded, through the European Gravitational Observatory (EGO), by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale di Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by institutions from Belgium, Germany, Greece, Hungary, Ireland, Japan, Monaco, Poland, Portugal, Spain. KAGRA is supported by Ministry of Education, Culture, Sports, Science and Technology (MEXT), Japan Society for the Promotion of Science (JSPS) in Japan; National Research Foundation (NRF) and Ministry of Science and ICT (MSIT) in Korea; Academia Sinica (AS) and National Science and Technology Council (NSTC) in Taiwan.
This paper was compiled using \textsc{showyourwork} \cite{Luger2021} to facilitate reproducibility.

\bibliography{bib.bib}

\end{document}
